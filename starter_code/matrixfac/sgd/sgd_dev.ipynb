{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Developing Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from linear_regressor import LinearRegressor\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sgd import sgd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your Goal: Design and implement a generalized SGD system which takes a `Trainable` model as an input, and trains the model using stochastic gradient descent.\n",
    "\n",
    "To help you work through this task, we will use a dummy dataset to test the model and your SGD implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine_data = pd.read_csv(\"./winequality-red.csv\")\n",
    "wine_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal is to predict the `quality` column of the wine, given all the other properties of the wine. To achieve this task, we will use a linear regressor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegressor(11, 3)\n",
    "weights, bias = model.parameters()\n",
    "print(f\"Weights: \\n{weights}\")\n",
    "print(f\"Bias: \\n{bias}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `weights` vector forms the coefficients of the linear regression plane of best fit (think slope) and `bias` is the vertical intercept term of the plane of best fit (offset from origin). We intialize these to small random numbers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First lets extract the data from the DataFrame into a numpy array that we can use to train the model. This consists of two steps:\n",
    "- Extracting the \"quality\" column as the set of actual values to predict with regression\n",
    "- Forming a numpy array out of the remainder columns (recalling that the linear regressor is initialized to take inputs vectors in $\\mathbb{R}^D$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truths = wine_data[\"quality\"].to_numpy(dtype=np.float64)\n",
    "wine_data.drop(\"quality\", axis=1, inplace=True)\n",
    "inputs = wine_data.to_numpy(dtype=np.float64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we'll split the entire dataset into a training set and testing set\n",
    "- The training set is used to train the model and learn the coefficients of the plane of best fit\n",
    "- The testing set is used to evaluate model performance on unseen data. **DO NOT use the testing set to train the model!** Otherwise we wouldn't know whether the plane of best fit is general enough!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(inputs, ground_truths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final step is to normalize the input data by feature. We want to normalize data as much as possible to decrease the variation in our inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(input):\n",
    "    return (input - np.mean(input, axis=0, keepdims=True)) / np.std(\n",
    "        input, axis=0, keepdims=True\n",
    "    )\n",
    "X_train = normalize(X_train)\n",
    "X_test = normalize(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will implement `sgd()` in the `sgd.py` file. The code below will run SGD on the linear regressor predicting the wine quality dataset and print out the loss. If you implemented SGD right, the model should be able to obtain a fairly low validation loss (I was able to achieve 0.364 error with using mean square error).\n",
    "\n",
    "**Challenge** (Something fun to try on your own): Try and get an even lower mean square error. See what this does to the predictions however, and why this may not be a great idea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd(model, X_train, y_train, batch_size = 128, num_iter=1000, learning_rate = 3e-3)\n",
    "print(model.loss(X_test, y_test))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b2c451bc85bb0ced6a55d0a4be54636bf64a73412d6d07082eec9d62daf3017b"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
